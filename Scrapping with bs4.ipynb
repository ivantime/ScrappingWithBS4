{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd7469c",
   "metadata": {},
   "source": [
    "# Proxy Rotation (Note: Use EliteProxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c4f2448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72b3048",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying proxy: https://47.240.160.90:10001\n",
      "Bad proxy...\n",
      "Trying proxy: https://195.158.30.232:3128\n",
      "Bad proxy...\n",
      "Trying proxy: https://5.161.105.105:80\n",
      "Bad proxy...\n",
      "Trying proxy: https://43.225.23.132:80\n",
      "Bad proxy...\n",
      "Trying proxy: https://150.136.108.121:3128\n",
      "Bad proxy...\n",
      "Trying proxy: https://85.25.91.141:15333\n",
      "Bad proxy...\n",
      "Trying proxy: https://85.195.104.71:80\n",
      "Bad proxy...\n",
      "Trying proxy: https://38.108.119.176:59394\n",
      "Bad proxy...\n",
      "Trying proxy: https://50.231.95.3:8080\n",
      "Bad proxy...\n",
      "Trying proxy: https://18.230.58.67:3128\n",
      "Bad proxy...\n",
      "Trying proxy: https://78.46.123.202:80\n",
      "Bad proxy...\n",
      "Trying proxy: https://5.189.184.6:80\n",
      "Bad proxy...\n",
      "Trying proxy: https://1.10.141.220:54620\n",
      "Bad proxy...\n",
      "Trying proxy: https://154.66.210.1:8080\n",
      "Bad proxy...\n",
      "Trying proxy: https://151.106.17.122:1080\n",
      "Bad proxy...\n",
      "Trying proxy: https://151.106.17.125:1080\n",
      "Bad proxy...\n",
      "Trying proxy: https://151.106.17.123:1080\n",
      "Bad proxy...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13184/981177349.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.google.com/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mproxy_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ip'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'url:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'json'"
     ]
    }
   ],
   "source": [
    "res = requests.get('https://free-proxy-list.net')\n",
    "content = BeautifulSoup(res.text, 'lxml')\n",
    "table = content.find('table')\n",
    "rows = table.find_all('tr')\n",
    "cols = [[col.text for col in row.find_all('td')] for row in rows]\n",
    "\n",
    "proxies = []\n",
    "proxy_index = 0\n",
    "\n",
    "for col in cols:\n",
    "    try:\n",
    "        if col[4] == 'elite proxy' and col[6] == 'yes':\n",
    "            proxies.append('https://' + col[0] + ':' + col[1])\n",
    "    except:\n",
    "        pass\n",
    "# print (proxies)\n",
    "\n",
    "def fetch(url, params):\n",
    "    global proxy_index\n",
    "    \n",
    "    while proxy_index < len(proxies):\n",
    "        try:\n",
    "            print('Trying proxy:', proxies[proxy_index])\n",
    "            res = requests.get(url, proxies={'https': proxies[proxy_index]}, params=params, timeout=5)\n",
    "            return res\n",
    "            \n",
    "        except:\n",
    "            print('Bad proxy...')\n",
    "            proxy_index += 1\n",
    "\n",
    "for page in range(0, 4):\n",
    "    params = {'page': page}\n",
    "    res = fetch('https://www.google.com/', params=params)\n",
    "    proxy_index += 1\n",
    "    print('ip', res.json()['ip'])\n",
    "    print('url:', res.json()['url'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cee9436",
   "metadata": {},
   "source": [
    "# Word Combinations (of 20 Words Given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "341ecfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6be7aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words2Scrap=[\"Table\", \"Fog\", \"Wikipedia\", \"Empire\", \"Ruin\", \"Era\", \"English\", \"Library\", \"Twin\", \"Tower\", \"Book\", \"Art\",\n",
    "             \"Science\", \"Poor\", \"Rich\", \"Dad\", \"Heart\", \"Power\", \"Medicine\", \"Borrow\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68e11ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#Source: https://stackoverflow.com/questions/464864/how-to-get-all-possible-combinations-of-a-list-s-elements#answer-32555776\n",
    "def combs(x):\n",
    "    return [c for i in range(len(x)+1) for c in combinations(x,i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "622b3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "lister= list(combs(words2Scrap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "726acc82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lister)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fd91a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatSearchTerm4url(typle,index):\n",
    "    searchTerm=\"\"\n",
    "    for i,d in enumerate(list(typle[index])):\n",
    "        if (i!=0):\n",
    "            searchTerm+=\"+\"+str(d)\n",
    "        else:\n",
    "            searchTerm=d\n",
    "    urlMain= f\"https://openlibrary.org/search?q=paper+trains&mode=everything\"\n",
    "    return urlMain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d96250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRobotDelay(num_runs,delayTime):\n",
    "    #every 10 runs/pages or if first time, get delay from robots.txt\n",
    "    if (num_runs%20==0 or delayTime==0):\n",
    "        res = requests.get('https://openlibrary.org/robots.txt')\n",
    "        content = BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "        delayTime = float(str(content).split(\"\\nCrawl-delay: \")[-1].split(\"\\n\")[0])\n",
    "        print(\"just got robot.txt... current delay time: \",delayTime)\n",
    "        return delayTime\n",
    "    else:\n",
    "        return delayTime\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c847287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "def getLinksOfPageURL(lister, index,urls, num_runs, delayTime):\n",
    "    delayTime = getRobotDelay(num_runs,delayTime)\n",
    "    \n",
    "    if (type(lister) is not str):\n",
    "        URL =formatSearchTerm4url(lister,index)\n",
    "        page = requests.get(URL)\n",
    "\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        job_elements = soup.find(class_=\"pagination\")\n",
    "\n",
    "        page_no=0\n",
    "\n",
    "        if (lister[index]!=()):\n",
    "            pages= job_elements.find_all(class_=\"ChoosePage\",href=True)\n",
    "\n",
    "            print(f\"\\n\\n\\n\\n\\n\\nURL of Index {index}...\")\n",
    "            for indexPage,data in enumerate(pages):\n",
    "                if (indexPage==0):\n",
    "                    #then add page 1 (since there's page 2)\n",
    "                    url=\"https://openlibrary.org\"+data['href'][:len(data['href'])-1]+\"1\"\n",
    "                    page_no=1\n",
    "                    print (\"Found URL:\", (url))\n",
    "                    urls.append(url)\n",
    "                    \n",
    "                    #starts with page 2 thus add this too\n",
    "                    url=\"https://openlibrary.org\"+data['href']\n",
    "                    print (\"Found URL:\",url )\n",
    "                    page_no=int(data.text)\n",
    "                    urls.append(url)\n",
    "                    \n",
    "                else:\n",
    "                    try:\n",
    "                        url=\"https://openlibrary.org\"+data['href']\n",
    "                        print (\"Found URL:\",url )\n",
    "                        page_no=int(data.text)\n",
    "                        urls.append(url)\n",
    "                        \n",
    "                        print(len(urls))\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "\n",
    "            if (page_no!=0):\n",
    "                url=\"https://openlibrary.org\"+data['href'][:len(data['href'])-1]+str(page_no)\n",
    "                print(\"zzzzz Sleeping for \",delayTime,\" sec(s), from Robot.txt\")\n",
    "                time.sleep(delayTime)\n",
    "                print(\"ooooo Awake Now\")\n",
    "                \n",
    "                getLinksOfPageURL(url,page_no,urls,int(page_no),delayTime)\n",
    "\n",
    "        else:\n",
    "            print(f\"NOTE: Lister's Index of {index} has ZERO elements!\")\n",
    "            return []\n",
    "    \n",
    "    else:\n",
    "        delayTime = getRobotDelay(num_runs,delayTime)\n",
    "        page = requests.get(lister)\n",
    "        \n",
    "        print(\"Total Pages So Far: \", index)\n",
    "        page_no=index\n",
    "\n",
    "        try:\n",
    "            page = requests.get(lister)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            job_elements = soup.find(class_=\"pagination\")\n",
    "\n",
    "            pages= job_elements.find_all(class_=\"ChoosePage\",href=True)\n",
    "\n",
    "            print(f\"\\nFrom Page {index}...\")\n",
    "            for indexPage,data in enumerate(pages):\n",
    "                    if (\"Next\" in data.text or \"First\" in data.text or \"Previous\" in data.text):\n",
    "                        pass\n",
    "                    elif (int(data.text)>page_no):\n",
    "                        url=\"https://openlibrary.org\"+data['href']\n",
    "                        print (\"Found URL:\",url )\n",
    "                        urls.append(url)\n",
    "                        print(len(urls))\n",
    "                        page_no=int(data.text)\n",
    "\n",
    "            print(\"zzzzz Sleeping for \",delayTime,\" sec(s), from Robot.txt\")\n",
    "            time.sleep(delayTime)\n",
    "            print(\"ooooo Awake Now\")\n",
    "            \n",
    "            getLinksOfPageURL(url,page_no,urls,int(page_no),delayTime)\n",
    "        except:\n",
    "            print(\"End Of the Line.... No More Next Page\")\n",
    "            print(urls)\n",
    "            return urls\n",
    "        return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad72e628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://openlibrary.org/search?q=paper+trains&mode=everything'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatSearchTerm4url(lister,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11456435",
   "metadata": {},
   "source": [
    "# Get Each Page's URL and store in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a44b618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just got robot.txt... current delay time:  0.5\n",
      "NOTE: Lister's Index of 0 has ZERO elements!\n",
      "TOTAL LENGTH OF URLS COLLECTED for keywords' () ' : 0\n",
      "just got robot.txt... current delay time:  0.5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "URL of Index 1...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=1\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=2\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=3\n",
      "3\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=4\n",
      "4\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=5\n",
      "5\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=6\n",
      "6\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=7\n",
      "7\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=8\n",
      "8\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=9\n",
      "9\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=10\n",
      "10\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=2\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Total Pages So Far:  10\n",
      "\n",
      "From Page 10...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=11&mode=everything\n",
      "11\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=12&mode=everything\n",
      "12\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=13&mode=everything\n",
      "13\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=14&mode=everything\n",
      "14\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=15&mode=everything\n",
      "15\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Total Pages So Far:  15\n",
      "\n",
      "From Page 15...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=16\n",
      "16\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=17\n",
      "17\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=18\n",
      "18\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=19\n",
      "19\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=20\n",
      "20\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "just got robot.txt... current delay time:  0.5\n",
      "just got robot.txt... current delay time:  0.5\n",
      "Total Pages So Far:  20\n",
      "\n",
      "From Page 20...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=21\n",
      "21\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=22\n",
      "22\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=23\n",
      "23\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=24\n",
      "24\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=25\n",
      "25\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Total Pages So Far:  25\n",
      "\n",
      "From Page 25...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=26&mode=everything\n",
      "26\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=27&mode=everything\n",
      "27\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=28&mode=everything\n",
      "28\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=29&mode=everything\n",
      "29\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=30&mode=everything\n",
      "30\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Total Pages So Far:  30\n",
      "\n",
      "From Page 30...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=31\n",
      "31\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=32\n",
      "32\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=33\n",
      "33\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=34\n",
      "34\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=35\n",
      "35\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Total Pages So Far:  35\n",
      "\n",
      "From Page 35...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=36\n",
      "36\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=37\n",
      "37\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=38\n",
      "38\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=39\n",
      "39\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=40\n",
      "40\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "just got robot.txt... current delay time:  0.5\n",
      "just got robot.txt... current delay time:  0.5\n",
      "Total Pages So Far:  40\n",
      "\n",
      "From Page 40...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=41\n",
      "41\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=42\n",
      "42\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=43\n",
      "43\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=44\n",
      "44\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=45\n",
      "45\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Total Pages So Far:  45\n",
      "\n",
      "From Page 45...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=46\n",
      "46\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=47\n",
      "47\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=48\n",
      "48\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=49\n",
      "49\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=50\n",
      "50\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Total Pages So Far:  50\n",
      "\n",
      "From Page 50...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=51\n",
      "51\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=52\n",
      "52\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=53\n",
      "53\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=54\n",
      "54\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=55\n",
      "55\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Total Pages So Far:  55\n",
      "\n",
      "From Page 55...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=56\n",
      "56\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=57\n",
      "57\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=58\n",
      "58\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=59\n",
      "59\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=60\n",
      "60\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "just got robot.txt... current delay time:  0.5\n",
      "just got robot.txt... current delay time:  0.5\n",
      "Total Pages So Far:  60\n",
      "\n",
      "From Page 60...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=61\n",
      "61\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=62\n",
      "62\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=63\n",
      "63\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=64\n",
      "64\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&mode=everything&page=65\n",
      "65\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Total Pages So Far:  65\n",
      "\n",
      "From Page 65...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=66&mode=everything\n",
      "66\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=67&mode=everything\n",
      "67\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=68&mode=everything\n",
      "68\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=69&mode=everything\n",
      "69\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=70&mode=everything\n",
      "70\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Total Pages So Far:  70\n",
      "\n",
      "From Page 70...\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=71&mode=everything\n",
      "71\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=72&mode=everything\n",
      "72\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=73&mode=everything\n",
      "73\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=74&mode=everything\n",
      "74\n",
      "Found URL: https://openlibrary.org/search?q=paper+trains&page=75&mode=everything\n",
      "75\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n"
     ]
    }
   ],
   "source": [
    "urlFile=[]\n",
    "for i in range(0,len(lister)):\n",
    "    #start with number of runs 0\n",
    "    urlFile.append(getLinksOfPageURL(lister,i,urlFile,i,0))\n",
    "    urlFile = [x for x in urlFile if x != []]\n",
    "    print(\"TOTAL LENGTH OF URLS COLLECTED for keywords\\'\",lister[i],\"\\' :\",len(urlFile))\n",
    "    \n",
    "    a = numpy.asarray(urlFile)\n",
    "    numpy.savetxt(f\"URLScrapedKeyWordsLinks.csv\", a, delimiter=\",\", fmt='%s')\n",
    "#     numpy.savetxt(f\"URLScrapedKeyWords_WITH_{len(urlFile)}_links.csv\", a, delimiter=\",\", fmt='%s')\n",
    "\n",
    "        \n",
    "#NOTE: total 2865 pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d80a65",
   "metadata": {},
   "source": [
    "# Get Each Page's URL from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3efe22f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=1\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=2\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=3\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=4\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=5\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=6\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=7\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=8\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=9\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=10\n",
      "https://openlibrary.org/search?q=paper+trains&page=11&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=12&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=13&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=14&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=15&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=16\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=17\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=18\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=19\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=20\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=21\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=22\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=23\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=24\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=25\n",
      "https://openlibrary.org/search?q=paper+trains&page=26&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=27&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=28&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=29&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=30&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=31\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=32\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=33\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=34\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=35\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=36\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=37\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=38\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=39\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=40\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=41\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=42\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=43\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=44\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=45\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=46\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=47\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=48\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=49\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=50\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=51\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=52\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=53\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=54\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=55\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=56\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=57\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=58\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=59\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=60\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=61\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=62\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=63\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=64\n",
      "https://openlibrary.org/search?q=paper+trains&mode=everything&page=65\n",
      "https://openlibrary.org/search?q=paper+trains&page=66&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=67&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=68&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=69&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=70&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=71&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=72&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=73&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=74&mode=everything\n",
      "https://openlibrary.org/search?q=paper+trains&page=75&mode=everything\n",
      "None\n",
      "Processed 76 lines.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "pageURLs = []\n",
    "with open('URLScrapedKeyWordsLinks.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are\\n{\", \".join(row)}')\n",
    "            pageURLs.append(row)\n",
    "            line_count += 1\n",
    "        else:\n",
    "            print(f'{row[0]}')\n",
    "            line_count += 1\n",
    "            pageURLs.append(row)\n",
    "    print(f'Processed {line_count} lines.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be934b98",
   "metadata": {},
   "source": [
    "# Get Each Book's URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "df140fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just got robot.txt... current delay time:  0.5\n",
      "\n",
      "\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "https://openlibrary.org/works/OL6729940W\n",
      "https://openlibrary.org/works/OL6729938W\n",
      "https://openlibrary.org/works/OL6729935W\n",
      "https://openlibrary.org/works/OL6729930W\n",
      "https://openlibrary.org/works/OL6729928W\n",
      "https://openlibrary.org/works/OL6729927W\n",
      "https://openlibrary.org/works/OL6729909W\n",
      "https://openlibrary.org/works/OL25294299W\n",
      "https://openlibrary.org/works/OL24162515W?edition=ia%3Apapertrainechoes0000phei\n",
      "https://openlibrary.org/works/OL6729934W\n",
      "https://openlibrary.org/works/OL6729921W\n",
      "https://openlibrary.org/works/OL6729933W\n",
      "https://openlibrary.org/works/OL6729924W\n",
      "https://openlibrary.org/works/OL18883167W\n",
      "https://openlibrary.org/works/OL11929301W\n",
      "https://openlibrary.org/works/OL18883166W\n",
      "https://openlibrary.org/works/OL25547462W\n",
      "https://openlibrary.org/works/OL6729929W\n",
      "https://openlibrary.org/works/OL6729910W\n",
      "https://openlibrary.org/works/OL6729916W\n",
      "\n",
      "\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "https://openlibrary.org/works/OL6729931W\n",
      "https://openlibrary.org/works/OL6729915W\n",
      "https://openlibrary.org/works/OL6729903W\n",
      "https://openlibrary.org/works/OL6729923W\n",
      "https://openlibrary.org/works/OL6729904W\n",
      "https://openlibrary.org/works/OL6729926W\n",
      "https://openlibrary.org/works/OL6729906W\n",
      "https://openlibrary.org/works/OL15958283W\n",
      "https://openlibrary.org/works/OL15961076W\n",
      "https://openlibrary.org/works/OL16187404W\n",
      "https://openlibrary.org/works/OL6729932W\n",
      "https://openlibrary.org/works/OL8460962W\n",
      "https://openlibrary.org/works/OL6729939W\n",
      "https://openlibrary.org/works/OL12008994M\n",
      "https://openlibrary.org/works/OL12415439W\n",
      "https://openlibrary.org/works/OL13532870W\n",
      "https://openlibrary.org/works/OL7930532W\n",
      "https://openlibrary.org/works/OL18889672W\n",
      "https://openlibrary.org/works/OL1869308W\n",
      "https://openlibrary.org/works/OL11598848W\n",
      "\n",
      "\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "https://openlibrary.org/works/OL17787125W?edition=ia%3Atwopapersonmanua00harr\n",
      "https://openlibrary.org/works/OL6563375W\n",
      "https://openlibrary.org/works/OL18889671W\n",
      "https://openlibrary.org/works/OL13300606W\n",
      "https://openlibrary.org/works/OL19044930W\n",
      "https://openlibrary.org/works/OL28324595W\n",
      "https://openlibrary.org/works/OL13575674W\n",
      "https://openlibrary.org/works/OL9612478W?edition=ia%3Ayorkshiresurname0000heyd\n",
      "https://openlibrary.org/works/OL7932668W\n",
      "https://openlibrary.org/works/OL28340260W\n",
      "https://openlibrary.org/works/OL13532858W\n",
      "https://openlibrary.org/works/OL13532841W\n",
      "https://openlibrary.org/works/OL13147414W?edition=ia%3Atrainingmemorya00coopgoog\n",
      "https://openlibrary.org/works/OL17089463W?edition=ia%3Ab21358497\n",
      "https://openlibrary.org/works/OL20208645W\n",
      "https://openlibrary.org/works/OL8999128W\n",
      "https://openlibrary.org/works/OL12100425M\n",
      "https://openlibrary.org/works/OL9691071W?edition=ia%3Atrainingturnstoe0000ainl\n",
      "https://openlibrary.org/works/OL6529877W\n",
      "https://openlibrary.org/works/OL17228791M\n"
     ]
    }
   ],
   "source": [
    "delayTime = 0\n",
    "bookURLs =[]\n",
    "for index, item in enumerate(pageURLs):\n",
    "    delayTime = getRobotDelay(index,delayTime)\n",
    "    print(\"\\n\\nzzzzz Sleeping for \",delayTime,\" sec(s), from Robot.txt\")\n",
    "    time.sleep(delayTime)\n",
    "    print(\"ooooo Awake Now\")\n",
    "            \n",
    "    page = requests.get(pageURLs[index][0]) #url\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find('ul', class_='list-books')\n",
    "    for item in results:\n",
    "        if (item.find(\"h3\") == -1):\n",
    "            pass\n",
    "        else:\n",
    "            url = \"https://openlibrary.org\"+item.find(\"a\")['href']\n",
    "            print(url)\n",
    "            bookURLs.append(url)\n",
    "    if (index ==2):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "7db6fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBookDetails(soup):\n",
    "    dict1={}\n",
    "    \n",
    "    try:\n",
    "        results = soup.find('div', class_='workDetails')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #get Book Title\n",
    "    try:\n",
    "        dict1['title'] = results.find(\"h1\",class_=\"work-title\").text\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #get Author of Book URL\n",
    "    try:\n",
    "        dict1[\"authorURL\"] = \"https://openlibrary.org\"+results.find(\"h2\",class_=\"edition-byline\").find(\"a\")['href']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #get Book Date\n",
    "    try:\n",
    "        dict1[\"date\"] = results.find(\"div\",  class_=\"smallest\").text.split(\" | \")[0]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Get Subject(s) Name, URL\n",
    "    try:\n",
    "        dictNest={}\n",
    "        subjects = results.find(\"div\",  class_=\"subjects-content\").find(\"span\",class_=\"clamp\").find_all(\"a\")\n",
    "        for index, subject in enumerate(subjects):\n",
    "            dictNest[index] = {\"name\":subject.text, \"href\": \"https://openlibrary.org\"+subject['href']}\n",
    "        dict1[\"subject\"]=dictNest\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Get Published Date\n",
    "    publish_date = soup.find(\"div\",class_=\"edition-omniline-item\").find(\"span\").text\n",
    "    dict1[\"publish_date\"] = publish_date\n",
    "    \n",
    "    \n",
    "    #Book Details Section\n",
    "    sections = soup.find(\"div\",  class_=\"edition-info\").find_all(\"div\",class_=\"section\")\n",
    "    for section in sections:\n",
    "        try:\n",
    "            published_in = section.findChild(\"p\").text\n",
    "            dict1['published_in'] = published_in.replace(\"\\n          \",\"\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            dewy = section.findChild(\"dl\")\n",
    "        try:\n",
    "\n",
    "\n",
    "            try:\n",
    "                for index,item in enumerate(dewy.find_all(\"dt\")):\n",
    "                    if (\"OCLC/WorldCat\" in dewy.find_all(\"dt\")[index].text):\n",
    "                        dict1[\"oclc_worldcat\"] = dewy.find_all(\"dd\")[index].text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                    if (\"ISBN\" in dewy.find_all(\"dt\")[index].text):\n",
    "                        dict1[\"isbn\"] = dewy.find_all(\"dd\")[index].text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                    if (\"Open Library\" in dewy.find_all(\"dt\")[index].text):\n",
    "                        dict1[\"open_library_id\"] = dewy.find_all(\"dd\")[index].text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "\n",
    "                    if (\"Dewey Decimal Class\" in dewy.find_all(\"dt\")[index].text):\n",
    "                        dict1[\"dewy_decimal_class\"] = dewy.findChild(\"dd\").text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "\n",
    "                    if  (\"Number of pages\" in dewy.find_all(\"dt\")[index].text):\n",
    "                        dict1[\"num_of_pages\"] = dewy.find_all(\"dd\")[index].text.replace(\"\\n\",\"\").replace(\" \",\"\").replace(\";\",\"\")\n",
    "                    if (\"Pagination\" in dewy.find_all(\"dt\")[index].text):\n",
    "                        dict1[\"pagination\"] = dewy.find_all(\"dd\")[index].text.replace(\" ;\\n\\n\",\"\")\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "\n",
    "    \n",
    "    return dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "e5f56acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just got robot.txt... current delay time:  0.5\n",
      "\n",
      "\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Saved CSV file as' OL6729940W.json'\n",
      "\n",
      "\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Saved CSV file as' OL6729938W.json'\n",
      "\n",
      "\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Saved CSV file as' OL6729935W.json'\n",
      "\n",
      "\n",
      "zzzzz Sleeping for  0.5  sec(s), from Robot.txt\n",
      "ooooo Awake Now\n",
      "Saved CSV file as' OL6729930W.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for index, item in enumerate(bookURLs):\n",
    "\n",
    "    delayTime = getRobotDelay(index,delayTime)\n",
    "    \n",
    "    print(\"\\n\\nzzzzz Sleeping for \",delayTime,\" sec(s), from Robot.txt\")\n",
    "    time.sleep(delayTime)\n",
    "    print(\"ooooo Awake Now\")\n",
    "    \n",
    "    page = requests.get(bookURLs[index]) #url\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    csvHere = getBookDetails(soup)\n",
    "    try:\n",
    "        with open(bookURLs[index].split(\"https://openlibrary.org/works/\")[1]+'.json', 'w') as outfile:\n",
    "            json.dump(csvHere, outfile)\n",
    "            \n",
    "        print(\"Saved CSV file as\\'\",bookURLs[index].split(\"https://openlibrary.org/works/\")[1]+'.json\\'')\n",
    "    except Exception as e:\n",
    "        print(\"Couldn't export to CSV for Book (URL)\"+bookURLs[index]+\"\\nStack Trace Here:\\n\")\n",
    "        print(e)\n",
    "        \n",
    "    #break after 4 saves\n",
    "    if (index == 3): break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
